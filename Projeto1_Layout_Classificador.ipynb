{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome:Lorran Caetano Machado Lopes\n",
    "\n",
    "Nome: N√≠vea de Abreu Dantas Lima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\lorra\\OneDrive\\√Årea de Trabalho\\Ciencia dos Dados\\P1\\TweetsClassifier\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'cocacola.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relev√¢ncia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@kchorrolooko @cocacola_br essa √© a melhor bat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@cocacola_br @_evertonalmeida #coquinhagelada ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@juliettefreirec @bbb @joaoluizpedrosa @cocaco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#nowplaying  \\n[  nicki minaj - super bass  ]\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#nowplaying  \\n[  nick jonas - spaceman  ]\\nen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@reprincesa_ temos uma oferta perfeita pra voc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@jaefson nossa! üî• quando o amor invade, √© semp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@cocacola_br porra arrasou, so ta o pre√ßo do m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@a_mxnds ei, espera um pouco. vamos deixar ess...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@juliaacc a cara do glamour. arrasaram muito üòé</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relev√¢ncia\n",
       "0  @kchorrolooko @cocacola_br essa √© a melhor bat...           0\n",
       "1  @cocacola_br @_evertonalmeida #coquinhagelada ...           1\n",
       "2  @juliettefreirec @bbb @joaoluizpedrosa @cocaco...           0\n",
       "3  #nowplaying  \\n[  nicki minaj - super bass  ]\\...           1\n",
       "4  #nowplaying  \\n[  nick jonas - spaceman  ]\\nen...           1\n",
       "5  @reprincesa_ temos uma oferta perfeita pra voc...           1\n",
       "6  @jaefson nossa! üî• quando o amor invade, √© semp...           1\n",
       "7  @cocacola_br porra arrasou, so ta o pre√ßo do m...           1\n",
       "8  @a_mxnds ei, espera um pouco. vamos deixar ess...           1\n",
       "9     @juliaacc a cara do glamour. arrasaram muito üòé           0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relev√¢ncia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @sysa86: @bbb @cocacola_br o bbb21 virou um...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@cocacola_br coca cola te amo meu refrigerante...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@karolinemourab tem vezes que a vontade bate, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@kikiilda sede de coquinha? clica aqui üëâ https...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sysa86 @bbb @cocacola_br exatamente e eu amo ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#nowplaying  \\n[  maroon 5 - beautiful mistake...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@carlabuenoe √© pra j√°! ü•∞ caminh√£o do desconto ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@bbb cineminha, coquinha gelada e amigos = mel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@ddeysi2 humm... almocinho top! üòã mas que tal ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@jenifer_alineee que tal uma mudan√ßa nos plano...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Relev√¢ncia\n",
       "0  rt @sysa86: @bbb @cocacola_br o bbb21 virou um...           0\n",
       "1  @cocacola_br coca cola te amo meu refrigerante...           1\n",
       "2  @karolinemourab tem vezes que a vontade bate, ...           1\n",
       "3  @kikiilda sede de coquinha? clica aqui üëâ https...           1\n",
       "4  @sysa86 @bbb @cocacola_br exatamente e eu amo ...           0\n",
       "5  #nowplaying  \\n[  maroon 5 - beautiful mistake...           1\n",
       "6  @carlabuenoe √© pra j√°! ü•∞ caminh√£o do desconto ...           1\n",
       "7  @bbb cineminha, coquinha gelada e amigos = mel...           1\n",
       "8  @ddeysi2 humm... almocinho top! üòã mas que tal ...           1\n",
       "9  @jenifer_alineee que tal uma mudan√ßa nos plano...           1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.554054\n",
       "0    0.445946\n",
       "Name: Relev√¢ncia, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Relev√¢ncia.value_counts(True) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "O produto em quest√£o √© a Coca-cola, e consideramos como relevantes os tweets que continham propagandas com promo√ß√µes, marca√ß√µes das pessoas que falavam tanto bem quanto teciam cr√≠ticas ao produto. Al√©m disso, consideramos como irrelevanes tweets que marcavam o produto de forma aleat√≥ria sem transmitir uma postagem coerente a men√ß√£o. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo definimos uma fun√ß√£o de limpeza para remover os caracteres: enter, :, \", ', (, ), etc e manter os emojis, al√©m de corrigir os espa√ßamentos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "from nltk.tokenize.casual import TweetTokenizer #importando....\n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Fun√ß√£o de limpeza\n",
    "        \n",
    "    \"\"\"\n",
    "    punctuation = '[\\[\\]@!-_.:?;]' #remo√ß√£o de pontua√ß√£o, @ e []\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    text_subbed = re.sub(' +', ' ', text_subbed)\n",
    "    text_subbed = text_subbed.lower()\n",
    "    text_subbed = re.sub(r'http\\S+', '', text_subbed) #remove links\n",
    "    t = TweetTokenizer()\n",
    "    text_subbed = t.tokenize(text_subbed) #remover emojissss\n",
    "    \n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = train.Treinamento[0]\n",
    "tweet_limpo = cleanup(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percorrendo os tweets para aplicar a fun√ß√£o de limpeza, seprarndo em listas de palavras\n",
    "relevante = []\n",
    "irrelevante = []\n",
    "\n",
    "j = 0\n",
    "for i in train.Treinamento:\n",
    "    tweetl = cleanup(i)\n",
    "    if train.Relev√¢ncia[j] == 1:\n",
    "        # Guardando as palavras dos tweets relevantes como lista \n",
    "        relevante += tweetl\n",
    "    else:\n",
    "        # Guardando as palavras dos tweets irrelevantes como lista \n",
    "        irrelevante += tweetl\n",
    "        \n",
    "    j += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando um conjunto com todas as palavras dos tweets relevantes e irrelevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardando as palavras relevantes em um pd.Series  \n",
    "serie_relevante = pd.Series(relevante)\n",
    "# Guardando as palavras irrelevantes em um pd.Series  \n",
    "serie_irrelevante = pd.Series(irrelevante)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequ√™ncias absolutas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Palavras em um texto s√£o vari√°veis **qualitativas nominais**, portanto usaremos `value_counts()` para obter a tabela de frequ√™ncias relativas e absolutas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como tabela_relevante √© uma pd.Series, podemos usar value_counts() nessa vari√°vel\n",
    "tabela_relevante = serie_relevante.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_irrelevante = serie_irrelevante.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequ√™ncias relativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_relevante_relativa = serie_relevante.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_irrelevante_relativa = serie_irrelevante.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = relevante + irrelevante\n",
    "todas_palavras = pd.Series(total)\n",
    "todas_palavras\n",
    "\n",
    "\n",
    "\n",
    "todas_palavras_relativa = todas_palavras.value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifica√ß√£o de um tweet: Relevante ou Irrelevante?\n",
    "\n",
    "Agora vamos ao problema que queremos resolver.\n",
    "\n",
    "Precisamos dizer se um dado tweetc√© mais prov√°vel de ser *Relevante* ou *Irrelevante*.\n",
    "\n",
    "Ou seja, precisa decidir: \n",
    "\n",
    "$\\quad \\Rightarrow$ Se $P(Relevante|tweet) > P(Irrelevante|tweet)$, ent√£o o tweet ser√° classificado como *Relevante*.\n",
    "\n",
    "$\\quad \\Rightarrow$ Se $P(Irrelevante|tweet) > P(Relevante|tweet)$, ent√£o o tweet ser√° classificado como *Irrelevante*.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "A partir deste ponto, vamos denotar $Relevante$ como $R$ e $Irrelevante$ como $I$ para brevidade.\n",
    "\n",
    "O **Teorema de Bayes** vai ser particularmente √∫til neste caso. Lembre-se que:\n",
    "\n",
    "$\\quad P(R|tweet) = \\frac{P(tweet|R)P(R)}{P(tweet)}$\n",
    "\n",
    "e que:\n",
    "\n",
    "$\\quad P(I|tweet) = \\frac{P(tweet|I)P(I)}{P(tweet)}$\n",
    "\n",
    "\n",
    "<br>\n",
    "Teremos que calcular **TODAS** as probabilidades que se encontram no lado direito das equa√ß√µes acima e com elas calcular $P(R|tweet)$ e $P(I|tweet)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweet exemplo fict√≠cio a classificar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tw = \"amo coquinha gelada\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amo', 'coquinha', 'gelada']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vamos converter primeiro em min√∫sculas e fazer a limpeza:\n",
    "tw = cleanup(tw.lower())\n",
    "tw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A ingenuidade - Na√Øve Bayes\n",
    "\n",
    "Agora vamos √† parte ing√™nua do Na√Øve Bayes, que consiste em assumir que as palavras s√£o independentes entre si e que sua ordem no tweet n√£o importa. \n",
    "\n",
    "\n",
    "Ou seja:\n",
    "\n",
    "$\\quad P(tweet|R) = \n",
    "P(odeio|R)\\cdot P(batata|R)\\cdot P(frita|R)$\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Vamos denotar **Relevante** simplesmente como $R$, para encurtar a f√≥rmula a seguir aplicando o uso do Teorema de Bayes.\n",
    "\n",
    "Assim, a f√≥rmula completa fica:\n",
    "\n",
    "$P(R|tweet) = \\frac{P(odeio|R).P(batata|R).P(frita|R).P(R)}{P(tweet)}$\n",
    "\n",
    "<br>\n",
    "\n",
    "Da mesma forma, denotando **Irrelevante** como $I$, a f√≥rmula completa fica:\n",
    "\n",
    "$P(I|tweet) = \\frac{P(odeio|I).P(batata|I).P(frita|I).P(I)}{P(tweet)}$\n",
    "<br>\n",
    "\n",
    "Note que o denominador das duas probabilidade condicionais acima √© o mesmo, para fazer a classifica√ß√£o da frase podemos cancelar o c√°lculo do denominador $P(tweet)$. \n",
    "\n",
    "Assim, a **Classifica√ß√£o do tweet** se dar√° conforme abaixo:\n",
    "\n",
    "$\\quad \\Rightarrow$ Se $P(R|tweet) > P(I|tweet)$, ent√£o frase ser√° classificada como *Relevante*\n",
    "\n",
    "$\\quad \\Rightarrow$ Se $P(R|tweet) < P(I|tweet)$, ent√£o frase ser√° classificada como *Irrelevante*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7243765316419202 0.2756234683580799\n"
     ]
    }
   ],
   "source": [
    "#CALCULANDO OS VALORES DOS PRIORS P(R) E P(I)\n",
    "total = len(relevante)+len(irrelevante) \n",
    "P_R = len(relevante)/total\n",
    "P_I = len(irrelevante)/total\n",
    "\n",
    "print(P_R, P_I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando os termos: \n",
    "\n",
    "$\\quad P(tweet|R)$\n",
    "\n",
    "e \n",
    "\n",
    "$\\quad P(tweet|I)$\n",
    "\n",
    "<br>\n",
    "\n",
    "Armazenando o valor de $P(tweet|R)$ e $P(tweet|I)$ nas vari√°veis `probTweetDadoR` e `probTweetDadoI`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9459888498400543e-08 4.578110960078212e-09\n"
     ]
    }
   ],
   "source": [
    "probTweetDadoR = 1\n",
    "probTweetDadoI = 1\n",
    "\n",
    "for i in tw:\n",
    "    probTweetDadoR *= tabela_relevante_relativa[i]\n",
    "    probTweetDadoI *= tabela_irrelevante_relativa[i]\n",
    "    \n",
    "print(probTweetDadoR, probTweetDadoI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando $P(L|frase)$ e $P(C|frase)$ como indicado acima. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.134005185302908e-08"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_R_dado_T = probTweetDadoR * P_R\n",
    "P_R_dado_T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2618348213448957e-09"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_I_dado_T = probTweetDadoI * P_I\n",
    "P_I_dado_T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Comparando as probabilidades acima, o tweet √© classificada como Relevante '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classificador(r, i):\n",
    "    if r > i:\n",
    "        return(\"Comparando as probabilidades acima, o tweet √© classificada como Relevante \" )\n",
    "    elif i > r:\n",
    "        return(\"Comparando as probabilidades acima, o tweet √© classificada como Irrelevante \")\n",
    "    else:\n",
    "        return(\"N√£o √© poss√≠vel dizer, as probabilidades s√£o iguais.\")\n",
    "    \n",
    "classificador(P_R_dado_T, P_I_dado_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suaviza√ß√£o de Laplace: E se a palavra n√£o estiver no conjunto universo? P(palavra|Universo)=0?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso apare√ßa uma palavra estranha ou que n√£o esteja na base de dados, precisamos amplificar nosse leque de equa√ß√µes utilizando um recurso matem√°tico conhecido como <b><em>Suaviza√ß√£o de Laplace</em></b>, que consiste em basicamente \"incluir\" a nova palavra no √¢mbito das probabilidades relativas de uma determinada palavra ser classificada como Relevante ou Irrelevante.\n",
    "\n",
    "Para realizar tal recurso, devemos analisar quantas vezes a palavra analisada aparece no absolutamente na comapra√ß√£o em quest√£o, seja relevante ou irrelavante, somar uma unidade (que evita o <b>0</b>) no numerador, e somar a quantidade de \"poss√≠veis palavras no denominador\", isto √© a quantidade de palavras √∫nicas pertencentes ao dataset de tweets relevantes ou irrelevantes. Matematicamente teremos:\n",
    "\n",
    "$$P(palavra1|R) = \\frac{F_{AR}+1}{P_{R}+P_p}$$\n",
    "\n",
    "$$P(palavra1|I) = \\frac{F_{AI}+1}{P_{I}+P_p}$$\n",
    "\n",
    "Onde: \n",
    "\n",
    "$ F_{AR}$: Frequ√™ncia absoluta da palavra na categoria relevante \n",
    "\n",
    "$ F_{AI}$: Frequ√™ncia absoluta da palavra na categoria irrelevante \n",
    "    \n",
    "$P_{R}$: Todas as palavras pertencentes aos tweets rotulados como relevantes\n",
    "    \n",
    "$P_{I}$: Todas as palavras pertencentes aos tweets rotulados como irrelevantes\n",
    "\n",
    "$P_p$: Todas as palavras poss√≠veis na base de dados de treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando isso, temos agora as probabilidades $P(tweet|R)$ e $P(tweet|I)$ adequadas para receber palavras novas em seu universo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pr = len(relevante)\n",
    "Pi = len(irrelevante)\n",
    "Pp = Pr + Pi\n",
    "\n",
    "\n",
    "def relevancia (tweet):\n",
    "    Far = 0\n",
    "    Fai = 0\n",
    "    probTweetDadoR = 1\n",
    "    probTweetDadoI = 1\n",
    "    for palavra in tweet:\n",
    "        Far = relevante.count(palavra)\n",
    "        Fai= irrelevante.count(palavra)\n",
    "        #print(Far)\n",
    "        probTweetDadoR *= (Far + 1)/(Pr + Pp) \n",
    "        probTweetDadoI *= (Fai + 1)/(Pi + Pp) \n",
    "    if probTweetDadoR > probTweetDadoI:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "classs = []\n",
    "for i in test[\"Teste\"]:\n",
    "    i = cleanup(i.lower())\n",
    "    classs.append(relevancia(i))\n",
    "\n",
    "classs = pd.Series(classs)\n",
    "test[\"Classificador\"] = classs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relev√¢ncia</th>\n",
       "      <th>Classificador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @sysa86: @bbb @cocacola_br o bbb21 virou um...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@cocacola_br coca cola te amo meu refrigerante...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@karolinemourab tem vezes que a vontade bate, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@kikiilda sede de coquinha? clica aqui üëâ https...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sysa86 @bbb @cocacola_br exatamente e eu amo ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>@roinuj_s √© muito amor envolvido! ü•∞ https://t....</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>@mazonnys que tal uma oferta para te ajudar a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>cocacola melhor refri do mundo. ü§§</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>@augustoscarpin oba! üî• mas n√£o se esque√ßa que ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>@xxjaqueline7 que tal coquinha com pizza? üëâ do...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  Relev√¢ncia  \\\n",
       "0    rt @sysa86: @bbb @cocacola_br o bbb21 virou um...           0   \n",
       "1    @cocacola_br coca cola te amo meu refrigerante...           1   \n",
       "2    @karolinemourab tem vezes que a vontade bate, ...           1   \n",
       "3    @kikiilda sede de coquinha? clica aqui üëâ https...           1   \n",
       "4    @sysa86 @bbb @cocacola_br exatamente e eu amo ...           0   \n",
       "..                                                 ...         ...   \n",
       "195  @roinuj_s √© muito amor envolvido! ü•∞ https://t....           0   \n",
       "196  @mazonnys que tal uma oferta para te ajudar a ...           1   \n",
       "197                  cocacola melhor refri do mundo. ü§§           1   \n",
       "198  @augustoscarpin oba! üî• mas n√£o se esque√ßa que ...           1   \n",
       "199  @xxjaqueline7 que tal coquinha com pizza? üëâ do...           1   \n",
       "\n",
       "     Classificador  \n",
       "0                0  \n",
       "1                0  \n",
       "2                1  \n",
       "3                1  \n",
       "4                0  \n",
       "..             ...  \n",
       "195              1  \n",
       "196              1  \n",
       "197              1  \n",
       "198              1  \n",
       "199              1  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test # a limpeza √© feita apenas para classificar. Mantemos o tweet original no DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.7"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Porcentagem de verdadeiros positivos (mensagens relevantes e que s√£o classificadas como relevantes)\n",
    "\n",
    "condicao1 = test.Relev√¢ncia == 1\n",
    "condicao2 = test.Classificador == 1\n",
    "porcentagem_vp = (test.Teste.loc[condicao1 & condicao2].count()/(test.Relev√¢ncia == 1).sum())*100\n",
    "porcentagem_vp.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.46"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Porcentagem de falsos positivos (mensagens irrelevantes e que s√£o classificadas como relevantes)\n",
    "\n",
    "condicao3 = test.Relev√¢ncia == 0\n",
    "porcentagem_fp = (test.Teste.loc[condicao3 & condicao2].count()/(test.Relev√¢ncia == 0).sum())*100\n",
    "porcentagem_fp.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.54"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Porcentagem de verdadeiros negativos (mensagens irrelevantes e que s√£o classificadas como irrelevantes)\n",
    "condicao4 = test.Classificador == 0\n",
    "porcentagem_vn = (test.Teste.loc[condicao3 & condicao4].count()/(test.Relev√¢ncia == 0).sum())*100\n",
    "porcentagem_vn.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.2992700729927"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Porcentagem de falsos negativos (mensagens relevantes e que s√£o classificadas como irrelevantes)\n",
    "porcentagem_fn = (test.Teste.loc[condicao1 & condicao4].count()/(test.Relev√¢ncia == 1).sum())*100\n",
    "porcentagem_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classificador</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relev√¢ncia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82.5</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.3</td>\n",
       "      <td>92.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classificador     0     1\n",
       "Relev√¢ncia               \n",
       "0              82.5  17.5\n",
       "1               7.3  92.7"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test.Relev√¢ncia, test.Classificador, normalize = \"index\").round(3)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classificador</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relev√¢ncia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.0</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>63.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classificador     0     1\n",
       "Relev√¢ncia               \n",
       "0              26.0   5.5\n",
       "1               5.0  63.5"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test.Relev√¢ncia, test.Classificador, normalize = True).round(3)*100 #em rela√ß√£o ao total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os percentuais obtidos demonstram que o classificador apresenta um desempenho bom, haja vista que\n",
    "ele acertou em aproximadamente 89,5% dos casos. Al√©m disso, ele acerta mais quando o tweet analisado √© relevante.\n",
    "\n",
    "Nosso classificador apresenta algumas limita√ß√µes, tais como n√£o interpretar corretamente sarcasmo e dupla nega√ß√£o. O sarcasmo √© compreendido por n√≥s pois ele est√° ligado a outros aspectos da comunica√ß√£o humana, como entona√ß√£o, gesticula√ß√£o. Falamos algo mas queremos dizer extamente o oposto. E nosso classificador n√£o consegue interpretar sarcasmo pois analisa apenas as palvras dos tweets, sem informa√ß√µes adicionais. Ele utiliza-se apenas de ferramentas matem√°ticas probabil√≠sticas.\n",
    "\n",
    "A ferramenta desenvolvida, mesmo apresntando um desempenho muito bom, pode vir a ser melhorada e tornar-se cada vez mais precisa. Para tanto, o financiamento do projeto deve continuar sendo realizado. Com mais financiamento, seria poss√≠vel, por exemplo, expandir a base de dados de treinamento, o que implicaria em melhora no desempenho do classificador. \n",
    " \n",
    "O classificador poderia ser utilizado em outros contextos, tais como, por exemplo, no diagn√≥stico de doen√ßas de um paciente. A base poderia ser a descri√ß√£o de sintomas e, a classifica√ß√£o, a doen√ßa diagnosticada. Isso seria √∫til para auxiliar os m√©dicos em seus diagn√≥sticos de pacientes.\n",
    "Outro cen√°rio de poss√≠vel uso do classificador seria na classifica√ß√£o de textos por √°rea de conhecimento. Por exemplo: um texto que contenha muitas repeti√ß√µes de palavras como \"derivada\" e \"integral\" poderia ser classificado como da √°rea de exatas. J√° um texto com alta repeti√ß√£o de palavras como \"c√©culas\" e \"mitoc√¥ndrias\" poderia ser classificado como da √°rea de biol√≥gicas. \n",
    "\n",
    "N√£o podemos usar o pr√≥prio classificador para gerar mais amostras de treinamento pois ele se restringe a apenas ferramentas matem√°ticas de probabilidade, que ignora todo o contexto do frase e tudo mais que est√° compreend√≠vel para n√≥s por quest√µes culturais. Al√©m disso, a classifica√ß√£o manual recebida pelo classificador na base Treinamento est√° sujeita ao vi√©s de quem a fez. Esse vi√©s seria retransmitido e diminuiria a acur√°cia do classificador. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Um importante passo no aprendizado de m√°quina √© trabalhar com uma boa base de dados\n",
    "para o treinamento e teste do seu classificador. Entretanto, √© razo√°vel pensar que a divis√£o\n",
    "de dados utilizada at√© aqui em nosso Classificador representa uma entre muitas poss√≠veis combina√ß√µes.\n",
    "Assim sendo, aqui o objetivo √© avaliar como os tweets contidos na base de dados\n",
    "treinamento podem interferir numa melhor ou n√£o t√£o boa classifica√ß√£o das mensagens\n",
    "contidas na base de teste. \n",
    "Sendo assim, iremos juntar todos os tweets e criar 100 novas divis√µes aleat√≥rias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "percentual_acuracia = [] #lista que guardar√° a acur√°cia de cada repeti√ß√£o do loop\n",
    "# novo df com todos tweets\n",
    "dftest = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "dftest = dftest.rename(columns={'Teste':'Todos'})\n",
    "dftrain = pd.read_excel(filename, sheet_name = 'Treinamento')\n",
    "dftrain = dftrain.rename(columns={'Treinamento':'Todos'})\n",
    "dfall = pd.concat([dftest,dftrain])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-e2d365b39863>:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test2[\"Classificador\"] = classs2\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    #separando em 2 aleatoriamente, e refazendo todo processo para guardar as acur√°cias\n",
    "    #separarando em treinamento e teste\n",
    "    train2, test2 = train_test_split(dfall, test_size=0.4)\n",
    "    #separando por relevancia\n",
    "    relevante2 = train2[train2['Relev√¢ncia']==1]\n",
    "    irrelevante2 = train2[train2['Relev√¢ncia']==0]\n",
    "    #criando listas com as palavras limpas \n",
    "    lista_relev2 = []\n",
    "    lista_irrelev2 = []\n",
    "    #limpa os tweets e cria banco de palavras relevantes e irrelevantes\n",
    "    for tweet in relevante2[\"Todos\"]:\n",
    "        tweetl = cleanup(tweet)\n",
    "        lista_relev2 += tweetl    \n",
    "    for tweet in irrelevante2[\"Todos\"]:\n",
    "        tweetl = cleanup(tweet)\n",
    "        lista_irrelev2 += tweetl \n",
    "    #Tamanho do universo relevante e irrelevante\n",
    "    Pr = len(relevante2)\n",
    "    Pi = len(irrelevante2)\n",
    "    #Tamanho total\n",
    "    Pp = Pr + Pi\n",
    "    #Definindo frequencia absoluta inicial \n",
    "    Far = 0\n",
    "    Fai = 0\n",
    "    #fun√ß√£o que classificar√° em 0 ou 1, irrelevante ou relevante pela suaviza√ß√£o de LaPlace\n",
    "    def relevancia2 (tweet):\n",
    "        Far = 0\n",
    "        Fai = 0\n",
    "        probTweetDadoR = 1\n",
    "        probTweetDadoI = 1\n",
    "        for palavra in tweet:\n",
    "            Far = lista_relev2.count(palavra)\n",
    "            Fai= lista_irrelev2.count(palavra)\n",
    "            probTweetDadoR *= (Far + 1)/(Pr + Pp) \n",
    "            probTweetDadoI *= (Fai + 1)/(Pi + Pp) \n",
    "        if probTweetDadoR > probTweetDadoI:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    #lista que guardar√° a classifica√ß√£o\n",
    "    classs2 = []\n",
    "    #limpa os tweets p/ classificar e classifica\n",
    "    for i in test2[\"Todos\"]:\n",
    "        i = cleanup(i.lower())\n",
    "        classs2.append(relevancia2(i))\n",
    "\n",
    "    #adicionando a coluna classifica√ß√£o com valores no df test2\n",
    "    test2[\"Classificador\"] = classs2\n",
    "    #condici√ß√µes para filtro e obter acur√°cia\n",
    "    condicao1n = test2.Relev√¢ncia == 1\n",
    "    condicao2n = test2.Classificador == 1\n",
    "    condicao3n = test2.Relev√¢ncia == 0\n",
    "    condicao4n = test2.Classificador == 0\n",
    "    porcentagem_vp = (test2.Todos.loc[condicao1n & condicao2n].count()/((test2.Relev√¢ncia == 0).sum()+(test2.Relev√¢ncia == 1).sum()))*100\n",
    "    #Porcentagem de verdadeiros negativos (mensagens irrelevantes e que s√£o classificadas como irrelevantes)\n",
    "    porcentagem_vn = (test2.Todos.loc[condicao3n & condicao4n].count()/((test2.Relev√¢ncia == 0).sum() + (test2.Relev√¢ncia == 1).sum()))*100\n",
    "    #salvando a acur√°cia em % na lista\n",
    "    percentual_acuracia.append(porcentagem_vp+porcentagem_vn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# faixas de AMPLITUDES IGUAIS\n",
    "faixa1 = np.arange(70,90,1.)\n",
    "faixa1\n",
    "\n",
    "# Histograma da vari√°vel acur√°cia em % considerando faixas de AMPLITUDES IGUAIS\n",
    "plt.hist(percentual_acuracia, bins=faixa1, edgecolor='white')\n",
    "plt.title('Acur√°cia do modelo')\n",
    "plt.ylabel('frequ√™ncia')\n",
    "plt.xlabel('Porcentagem de acerto(%)')\n",
    "plt.xlim(70,90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O m√≠nimo da acur√°cia foi de 72.37 %\n",
      "O m√°ximo da acur√°cia foi de 85.53 %\n",
      "A m√©dia da acur√°cia foi de 79.11 %\n"
     ]
    }
   ],
   "source": [
    "percentual_acuracia = pd.Series(percentual_acuracia)\n",
    "print(f'O m√≠nimo da acur√°cia foi de {percentual_acuracia.min():.2f} %')\n",
    "print(f'O m√°ximo da acur√°cia foi de {percentual_acuracia.max():.2f} %')\n",
    "print(f'A m√©dia da acur√°cia foi de {percentual_acuracia.mean():.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseando-se no histograma acima, √© poss√≠vel observar uma varia√ß√£o consider√°vel da acur√°cia para varia√ß√µes das planilhas de teste e treinamento. Logo √© possiv√©l concluir que ao tomar apenas um √∫nico arranjo das bases, h√° o risco de tanto chegar numa acur√°cia mais baixa que a melhor poss√≠vel quanto de ficar pr√≥xima da m√©dia. Assim, fica ressaltada a desvantagem de dividir a base s√≥ uma √∫nica vez, visto que essa divis√£o tem grande probabilidade de n√£o ser a melhor poss√≠vel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.datageeks.com.br/naive-bayes/ **Outro contexto de aplica√ß√£o**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
